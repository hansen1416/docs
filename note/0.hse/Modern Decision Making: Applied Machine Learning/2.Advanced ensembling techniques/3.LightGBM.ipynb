{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM: Light Gradient Bossting machine\n",
    "\n",
    "Proposed new features such as __leaf-wise__ tree growth\n",
    "\n",
    "Level-wise: like in gradient boosting, grow trees at level3, and then level 4, level 5.\n",
    "\n",
    "Leaf-wise: Each time you calculate where to split a node. On each step, we split the node of the tree with no children which maximally reduces impurity.\n",
    "\n",
    "__GOSS: Gradient-based One-side sampling__\n",
    "\n",
    "$s_i^{(N)} = -\\frac{\\partial}{\\partial z} L(y_i, z)|_{z=a_{N-1}}(x_i)$\n",
    "\n",
    "If $|s_i^{(N)}|$ is small, we may exclude $x_i$ from training  \n",
    "If $|s_i^{(N)}|$ is large, we should continue to train on $x_i$\n",
    "\n",
    "Downsampling: less correlated models, regularizatin. (may throw out some observations, so don't overfit on already good model)\n",
    "\n",
    "1. Keep observation with large gradients\n",
    "2. Perform random sampling for instances with small gradients\n",
    "3. Data distribution is modified, so use $\\frac{1-a}{b}$ multiplying coefficient while computing informatin again, where $a$ and $b$ are sampling ratios of large/small gradient observations.\n",
    "\n",
    "__Exclusive feature building__\n",
    "\n",
    "High dimensional data can be sparse, so we can reduce the number of features\n",
    "\n",
    "We can find exclusive sparse features - which do not take non-zero values simultaneously - and bundle them into one. (take many exclusive features, build into one)\n",
    "\n",
    "1. Construct a graph with weighted edges. Weights correspond to the total conflicts between features.\n",
    "\n",
    "2. Sort features by their node degrees in the descending order.\n",
    "\n",
    "3. Assign each feature to an existing bundle with a small conflict or create a new bundle.\n",
    "\n",
    "__Histogram-based splitting__\n",
    "\n",
    "How to find a split for a feature which takes 30000 values?\n",
    "\n",
    "Solution: Build a histogram and run through the bins (control number of bins. It significantly reduces the number of considered unique values for splitting the node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Summary__\n",
    "\n",
    "LightBGM has different features to make it more optimal in terms of accuracy and speed\n",
    "\n",
    "Leaf-wise tree growth allows to grow more accurate trees\n",
    "\n",
    "GOSS, EFB and Histogram-based splitting are aimed at reducing computational complexity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
