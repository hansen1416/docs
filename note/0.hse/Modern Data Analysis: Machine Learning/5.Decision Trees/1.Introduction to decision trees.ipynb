{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance of Non-Linear Models\n",
    "\n",
    "Assume we have 10 features.\n",
    "\n",
    "Polynomial of power 2 $\\to$ 55 extra features.\n",
    "\n",
    "Polynomial of power 3 $\\to$ 220 extra features.\n",
    "\n",
    "such model overfit quite easily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## complexity of decision tree\n",
    "\n",
    "- We can keep splitting until we have only one object in each leaf\n",
    "- We can ideally fit __any__ training data\n",
    "- Unless there are several objects with the same features and different target values\n",
    "\n",
    "---\n",
    "\n",
    "- Decision trees - combination of simple logic rules\n",
    "- Decision trees split feature space into several areas with constant prediction in each of them\n",
    "- It is quit easy to overfit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predictions in leaves: Regression\n",
    "\n",
    "- We will use constant predictions $c_v\\in \\mathbb{Y}$\n",
    "\n",
    "- Average value:\n",
    "\n",
    "$c_v = \\frac{1}{|R_v|} \\sum_{(x_i,y_i) \\in R_v} y_i$\n",
    "\n",
    "## predictions in leaves: Classification\n",
    "\n",
    "- We will use constant predictions $c_v\\in \\mathbb{Y}$\n",
    "\n",
    "- The most common class:\n",
    "\n",
    "$c_v = argmax_{k\\in \\mathbb{Y}} \\sum_{(x_i,y_i) \\in R_v} [y_i=k]$\n",
    "\n",
    "- Class probabilities\n",
    "\n",
    "$c_{vk} = \\frac{1}{|R_v|} \\sum_{(x_i,y_i) \\in R_v} [y_i=k]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree: interpretation\n",
    "\n",
    "- Tree splits feature space on disjoint sub-spaces $R_1,\\dots, R_J$\n",
    "\n",
    "- Each sub-space $R_j$ corresponds to the leaf\n",
    "\n",
    "- At each sub-space $R_j$ prediction $c_j$ is constant\n",
    "\n",
    "$a(x)=\\sum^{J}_{j=1}c_j[x\\in R_j]$\n",
    "\n",
    "- Decision tree constructs new powerful features\n",
    "\n",
    "- Therefore, the predictions is a linear combination of new features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
