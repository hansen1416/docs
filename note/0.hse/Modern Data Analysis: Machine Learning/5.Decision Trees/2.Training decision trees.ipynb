{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy\n",
    "\n",
    "We consider entropy as a way to measure the uncertainty of an experiment's outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Low entropy')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "ax1.bar([1,2,3,4,5], [3,3,3,3,3])\n",
    "ax1.set_title('High entropy')\n",
    "ax1.set_ylim([0,6])\n",
    "\n",
    "\n",
    "ax2.bar([1,2,3,4,5], [1,0,1,6,1])\n",
    "ax2.set_title('Low entropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume we are given discrete distribution with $n$ possible outcomes.\n",
    "\n",
    "Probability of outcomes: $p_1,p_2,\\dots,p_n$\n",
    "\n",
    "Entropy of distribution: $H(p_1,\\dots,p_n) = -\\sum^{n}_{i=1}p_i \\log_2 p_i$\n",
    "\n",
    "---\n",
    "\n",
    "- In classification tasks, the number of possible outcomes is the number of classes $K$.\n",
    "\n",
    "- Probability to be at the class $k$ - fraction of objects of class $k$\n",
    "\n",
    "    $p_k=\\frac{1}{|R|} \\sum_{(x_i,y_i)\\in R}[y_i=k]$\n",
    "\n",
    "- Zero entropy, there are __only__ objects from __one class__ at the leaf\n",
    "\n",
    "- Max entropy, there are __equal proportion__ of objects from __each class__.\n",
    "\n",
    "---\n",
    "\n",
    "Choose split with lower total entropy.\n",
    "\n",
    "- Decision tree could be constructed in a greedy manner from the root node to the leaves.\n",
    "- For classification task we could choose a split, so that it minimize class diversity at resulting groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measures of Impurity\n",
    "\n",
    "### Gini index\n",
    "\n",
    "$H(p_1,\\dots,p_k) = \\sum^{K}_{i=1}p_i(1-p_i)$\n",
    "\n",
    "- Consider a classifier, which outputs class $k$ with probability $p_k$\n",
    "\n",
    "- Gini index is a probability that the object will be classfied __incorrectly__ if the class is assigned with probabilities $H(p_1,\\dots,p_k)$.\n",
    "\n",
    "### Impurity criterions\n",
    "\n",
    "- Compare the impurity before the split and in the two nodes after the split.\n",
    "\n",
    "$Q(R,j,t) = H(R)-\\frac{|R_j|}{|R|}H(R_j) - \\frac{|R_r|}{|R|}H(R_r) \\to max_{j,t}$ (decrease impurity as much as possible)\n",
    "\n",
    "- Entropy and gini for Classification tasks.\n",
    "- For regression tasks, $H(R)$ can also be variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H(R) = min_c\\frac{1}{|R|}\\sum_{y\\in R}l(y,c)$ impurity cretirion\n",
    "\n",
    "__Impurity Criterion for Regression__\n",
    "\n",
    "$l(y,c) = (y-c)^2$ loss function\n",
    "\n",
    "$min_c\\frac{1}{|R|} \\sum_{y \\in R}(y-c)^2 \\implies c^* = \\bar{y} = \\frac{1}{|R|}\\sum_{y\\in R}y$ optimal value for constant prediction.\n",
    "\n",
    "$H(R) = \\frac{1}{|R|} \\sum_{y \\in R}(y-\\bar{y})^2$ formula for the variance\n",
    "\n",
    "__Impurity Criterion for Classification__\n",
    "\n",
    "$\\mathbb{Y} = \\{1,\\dots, K\\}$\n",
    "\n",
    "$P_k = \\frac{1}{|R|}\\sum_{y\\in R}[y=k]$ proportion of objects in this class.\n",
    "\n",
    "We have two options, A predict a class or B predict distribution of each class\n",
    "\n",
    "A. $c\\in \\{1,\\dots, K\\}$\n",
    "\n",
    "B. $c = (c_1, \\dots, c_K), \\sum^{K}_{k=1}c_k=1$\n",
    "\n",
    "A: \n",
    "\n",
    "$l(y,c) = [y\\neq c]$\n",
    "\n",
    "$min_c\\frac{1}{|R|} \\sum_{y\\in R}[y \\ne c] \\implies c^* = argmax_k P_k \\implies k^*$\n",
    "\n",
    "$H(R) = \\frac{1}{|R|} \\sum_{y\\in R} [y\\ne k^*]$ what is the proportion of objects which does not belong to the most popular class, $k^*$\n",
    "\n",
    "$=1-P_{k^*}$\n",
    "\n",
    "such measure of impurity is actually not a really good idea. e.g.  case 1 [0.7,0.3,0], case 2 [0.7,0.15,0.15], \n",
    "$1-P_{k^*}$ is the same for both cases, but case 1 is better in practice.\n",
    "\n",
    "B:\n",
    "\n",
    "$l(y,c) = - \\log(\\prod^K_{k=1}c^{[y=k]}_k) = -\\sum^K_{k=1} [y=k] \\log c_k$\n",
    "\n",
    "$min_c = \\frac{1}{|R|} \\sum^K_{k=1} [y=k] \\log c_k$, s.t. $\\sum^K_{k=1} c_k = 1$\n",
    "\n",
    "$c^* = (p_1, \\dots, p_k)$ optimal solution equal exactly to the proportion of observations that we have in our set.\n",
    "\n",
    "__$H(R) = -\\sum^K_{k=1} p_k(\\log p_k)$__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy Tree Construction\n",
    "\n",
    "__Stop criterions__\n",
    "\n",
    "- Restrict the maximal depth\n",
    "- Restrict the number of leaves\n",
    "- Fix the minimal number of objects in the node\n",
    "- Set the minimal decrease in the diversity when splitting.\n",
    "\n",
    "__Greedy Algorithm__\n",
    "\n",
    "1. Put the whole dataset into the root: $R_1= X$\n",
    "\n",
    "2. Start the tree construction: SplitNode$(1,R_1)$\n",
    "\n",
    "SplitNode$(1,R_1)$:\n",
    "\n",
    "1. If stopping criterion is met, then quit\n",
    "\n",
    "2. Find the best split (feature and threshold): $j,t=argmax_{j,t}Q(R_m,j,t)$\n",
    "\n",
    "3. Split objects: $R_l = \\{ (x,y) \\in R_m | [x_j < t] \\}, R_r = \\{ (x,y) \\in R_m | [x_j \\ge t]\\} $\n",
    "\n",
    "4. Repeat for the child nodes: SplitNode$(l, R_l)$ and SplitNode$(r, R_r)$\n",
    "\n",
    "The algorithm is quite complex and requires brute force of all the split at each step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## High Variance of Decision Trees\n",
    " \n",
    " High variance and lack of smoothness"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
