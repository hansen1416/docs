{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design A: $x_1, x_2, \\ldots , x_n \\sim X\\;\\;\\mathbb{E}X = \\mu_x \\;\\; VarX < \\infty$  \n",
    "\n",
    "Design B: $y_1, y_2, \\ldots , y_n \\sim Y\\;\\;\\mathbb{E}Y = \\mu_y \\;\\; VarY < \\infty$   \n",
    "\n",
    "$H_0: \\mu_x = \\mu_y$\n",
    "\n",
    "$H_1: \\mu_x \\ne \\mu_y$\n",
    "\n",
    "$\\bar{x}, \\bar{y} - sample averages$\n",
    "\n",
    "T-statistics for 2 samples\n",
    "\n",
    "$t(x,y) ={\\large \\frac{\\bar{x} - \\bar{y}}{\\sqrt{\\frac{Var_{+}x}{n}+\\frac{Var_{+}y}{m}}} } \\sim $ T-distribution\n",
    "\n",
    "$P(|t| > t_{critical}) = \\alpha$\n",
    "\n",
    "If $|t(x_{obs}, y_{obs})| > t_{critical} \\implies $ reject $H_0$\n",
    "\n",
    "p-value$(x_{obs}, y_{obs}) = P(|t| \\ge |t(x_{obs}, y_{obs})|)$\n",
    "\n",
    "p-value $< \\alpha \\implies $ reject $H_0$\n",
    "\n",
    "If we reject $H_0$ we say that difference in means in our samples is __statistically significant__   \n",
    "\n",
    "If diff is not significantï¼Œ probably we need more data to see it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a general framework of statistical hypothesis testing applied to our problem of comparing of means for two samples. \n",
    "\n",
    "When we use this method, we assume that either our samples are large enough or our data, our x and y are close enough to normal distributions because in this case, this correspondence works. \n",
    "\n",
    "In this case our t-distribution is actually distributed under this law. When we do not have large enough samples and we expect that our random variables are far from normally distributed, then it is probably better to use different ways to compare the corresponding samples, not to use t-test, but to use alternative also called non-parametric test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:  \n",
    "\n",
    "_This is incorrect interpretation of p-value. Null hypothesis is either true or not, it is not a matter of probability at all (at least, in the frequentiest statistics we study right now)._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_example_\n",
    "\n",
    "Find the value of t-statistics in two-sample t-test for samples: (2, 4, 6, 1, 3, 1, 4) and (3, 6, 2, 5, 7, 7). Use formula from the video. Enter numeric value with 2 digits after the decimal point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.8185396927681365"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = [2, 4, 6, 1, 3, 1, 4]\n",
    "y = [3, 6, 2, 5, 7, 7]\n",
    "\n",
    "x_bar = np.mean(x)\n",
    "y_bar = np.mean(y)\n",
    "\n",
    "x_var = np.var(x, ddof=1)\n",
    "y_var = np.var(y, ddof=1)\n",
    "\n",
    "n = len(x)\n",
    "m = len(y)\n",
    "\n",
    "t_stat = (x_bar - y_bar) / np.sqrt(x_var/n + y_var/m)\n",
    "t_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind, ttest_rel, ttest_1samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-2.705267164652239, pvalue=0.02655792987229184)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample1 = [3,4,5,6,3,4,5,2,3,4]\n",
    "sample2 = [8,9,10,30,7,8,11,20,50]\n",
    "\n",
    "ttest_ind(sample1, sample2, equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I switch this variables, I will get the same P value. Because in this function t-test in just like previously we use symmetrical alternative on the same two tailed t-test. But the value of the statistics is different. This differs by design. \n",
    "\n",
    "So if you want just a two tailed t-test, you can use this function. And if you want one tail test just like previously, you can use this function. But you can safely divide the corresponding value by two.\n",
    "\n",
    "__What you cannot do is the following. You cannot look at the data and then decide which alternative to use.__ You cannot do it because in this case. You will produce innocence, wrong results wrong from statistical point of view. Your procedure will not have the guarantees that we have initially. They guarantees about the probability of mistake. So you cannot look at the data before you stated your hypothesis. \n",
    "\n",
    "Of course, in practice it is in a sense an iterative process. Sometimes we make exploratory data analysis. We look at the data we draw some graphs, and then we stated some hypothesis. But you cannot test this hypothesis on the same data that you used to state them. \n",
    "\n",
    "__One way to overcome this issue is to divide your data set to several parts.__ For example 2 two parts. And it was __one part to do exploratory data analysis. And another part to test the hypothesis that you made when looking at the first part.__ This is correct procedure. But your cannot make rigorous statistical statements if you use the same data to stay hypothesis and test them. Do not do it because it is a violation of principles of statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-9.623189997698113, pvalue=1.9624057660484677e-08)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[47, 48, 51, 52, 52, 50, 47, 46, 52, 48, 49, 55, 52, 49, 52, 47, 50, 53, 48, 52]\n",
    "b=[60, 58, 61, 61, 54, 57, 59, 63, 60, 61]\n",
    "\n",
    "ttest_ind(a, b, equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-0.3038412337952006, pvalue=0.771511604086447)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = [300, 320, 200, 700]\n",
    "s2 = [350, 370, 240, 750]\n",
    "\n",
    "ttest_ind(s1, s2, equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=19.0, pvalue=0.00031834344007115753)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = [50, 50, 40, 50]\n",
    "ttest_1samp(diff, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-19.0, pvalue=0.00031834344007115753)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_rel(s1, s2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
