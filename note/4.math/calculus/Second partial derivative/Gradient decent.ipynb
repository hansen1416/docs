{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function's gradient is the vector of first partial derivative\n",
    "\n",
    "- Gradient is a point-wise concept\n",
    "\n",
    "- The direction of maximal growth at given point is the gradient at this point "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also consider the geometry between the gradient and function's level at given point\n",
    "\n",
    "$ f(x,y) = C $\n",
    "\n",
    "$ df=0 $\n",
    "\n",
    "$ f^{\\prime}_x(a,b)dx + f^{\\prime}_y(a,b)dy = 0 $\n",
    "\n",
    "$ (\\nabla f(a,b), (dx,dy)) = 0 $\n",
    "\n",
    "Since (dx, dy) is the level's tangent vector, we get that level and gradient are orthogonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Idea and motivation__\n",
    "\n",
    "Choose initial point $\\vec{x_0}$\n",
    "\n",
    "Go to the opposite direction of the gradient at point $\\vec{x_0}$, the step:\n",
    "\n",
    "$ \\vec{x_{n+1}} = \\vec{x_{n}} + \\alpha \\nabla f(\\vec{x_n}) $\n",
    "\n",
    "Stop in case of stabilization or small gradient length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Loss function__\n",
    "\n",
    "$ Loss(\\vec{w}) = \\frac{1}{N} \\sum^{N}_{i=1}(y_i - \\hat{y_i})^2$\n",
    "\n",
    "In order to be able to predict the target which is close to the actual one with our model, we need to __minimize__ the loss by finding a better set of weights. Loss is a multivariate function from weights. As you know from the lectures, to minimize it, we may use __gradient descent__. This includes finding the gradient of this multivariate function.\n",
    "\n",
    "__Loss function returns quantitative estimation of the quality of such prediction comparing y and the target predicted by x and model__. Note: we consider only model's parameters as variables of the Loss function since that is the only free (not given) instance in our setup!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Idea of Optimization__\n",
    "\n",
    "Normally one constructs the loss function as an error rate so it is essential to try to minimize it. In the same time it is always good idea to check whether or not greater values of your Loss function punish you for error or reward you for more accurate prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Gradient estimation__\n",
    "\n",
    "Underlying principle of the gradient descent is that function's gradient is the direction of maximal growth (hence, anti-gradient is the direction of fastest descent). Thus one need to calculate the gradient of the Loss function at the arbitrary point of the parameter space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Iteration__\n",
    "\n",
    "Assume you currently at the parameter point $w_k$. The next point should be chosen as\n",
    "\n",
    "$ w_{k+1} = w_k - \\alpha_k \\nabla \\, Loss(x,y,w_k) $\n",
    "\n",
    "where $\\alpha_k$ is the step length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__stratergy of step length__\n",
    "\n",
    "Too small $α_k$⟹ Too long convergence\n",
    "\n",
    "Too large $α_k$⟹ Jumps over minima⟹ Too long convergence\n",
    "\n",
    "One could go with:\n",
    "\n",
    "- constant step;\n",
    "- decreasing step ~ 1/k\n",
    "- \"vompal wabbit\" (power law step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Stop condition__\n",
    "\n",
    "One should choose the condition of exiting iterations:\n",
    "\n",
    "- small gradient length;\n",
    "- small enough (problem dependent!) Loss function value;\n",
    "- convergence of the $w_k$ Note: always limit the number of iterations by maxiter! It will prevent infinite loops during debug and in non convergent cases.\n",
    "- __Leaving local minima__ Described procedure does not guarantee that it will not converge to local minima. To avoid it, one can choose several initial points (e.g. randomly) and compare results after all attempts converge. Alternatively, during the stabilisation (or before leaving the iteration procedure when you decide that the method has converge) one could slightly perturb parameters and proceed with iterations (ideally, it should fastly fall into the same minimum)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: if only we were a circle\n",
    "--\n",
    "\n",
    "Consider the case of 2 parameter model with levels of two loss functions represented by circles and long and narrow ellipses respectively.\n",
    "\n",
    "- How do you think, in which case will we need less iterations?\n",
    "- It's quite easy to turn ellipse to circle and vice versa, right? We just need to scale an axis! What is the analogous transformation for the initial data X?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
