{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pod is the lowest unit of an application in Kubernetes. Now, before we move on, we need to get one thing straight â€” and that is a pod is not equal to a container in the Docker world. A pod can be made up of multiple containers. If you have come from a pure Docker background, this can be hard to wrap your head around. If a pod can have more than one container, how does it work? There are some limits we need to be aware of. \n",
    "\n",
    "A pod has the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A single IP address\n",
    "\n",
    "- Share localhost\n",
    "\n",
    "- A shared IPC space\n",
    "\n",
    "- A shared network port range\n",
    "\n",
    "- Shared volumes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The containers in a pod talk to each other via local host, whereas pod-to-pod communication is done via services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deploy `nginx` as a Pod named `nginx-1`\n",
    "```\n",
    "kubectl create deployment --image nginx nginx-1\n",
    "```\n",
    "This command creates a Pod named nginx with a container running the nginx image. When a repository isn't specified, the default behavior is to try and find the image either locally or in the Docker public registry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "kubectl get pods\n",
    "```\n",
    "\n",
    "Pod phases:\n",
    "- Pending, when image is pulling\n",
    "- Running, starting, restaring or running continuously\n",
    "- Succeeded, all containers have finished running successfully. In other words, they've terminated successfully and they won't be restarting.\n",
    "- Failed\n",
    "- Unkonwn, state of a pod simply cannot be retrieved. Probably because of a communication error between the master and the kubelet.\n",
    "- CrashLoopBackOff, one of the containers in the pod exited unexpectedly, even after it was restarted at least once. Usually pod isn't configured correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "kubectl describe pod [POD_NAME]\n",
    "```\n",
    "\n",
    "Pod:  \n",
    "Name  \n",
    "Namespace   \n",
    "Node name  \n",
    "Labels  \n",
    "Status  \n",
    "IP Address, etc  \n",
    "  \n",
    "Container:  \n",
    "State (waiting, running, terminated)  \n",
    "Images  \n",
    "Ports  \n",
    "Commands  \n",
    "Restart counts, etc  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "kubectl exec [POD_NAME] -- [command]\n",
    "\n",
    "kubectl exec demo env\n",
    "kubectl exec demo ps aux\n",
    "kubectl exec demo cat /proc/1/mounts\n",
    "kubectl exec demo ls /\n",
    "\n",
    "kubectl exec -it [POD_NAME] -- [command]\n",
    "\n",
    "```\n",
    "\n",
    "The -i argument tells kubectl to pass the terminal's standard input to the container, and the -t argument tells kubectl that the input is a TTY.\n",
    "\n",
    "If you don't use these arguments, then the exact command will be executed in the remote container and returned immediately to your local shell.\n",
    "\n",
    "If a pod has more one container, use the -c argument to specify the specific container to attach into the pod."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "kubectl logs [POD_NAME]\n",
    "```\n",
    "\n",
    "logs inlcude\n",
    "\n",
    "- stdout\n",
    "\n",
    "    Standard output on the console\n",
    "\n",
    "- stderr:\n",
    "\n",
    "    Error messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "copy file to container in pod\n",
    "```\n",
    "kubectl cp ~/test.html $my_nginx_pod:/usr/share/nginx/html/test.html\n",
    "```\n",
    "\n",
    "This command copies the test.html file from the local home directory to the /usr/share/nginx/html directory of the first container in the nginx Pod. You could specify other containers in a multi-container Pod by using the -c option, followed by the name of the container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expose the Pod for testing\n",
    "--\n",
    "\n",
    "create a service to expose our nginx Pod externally\n",
    "```\n",
    "kubectl expose pod $my_nginx_pod --port 80 --type LoadBalancer\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "view the resources being used by the nginx Pod\n",
    "```\n",
    "kubectl top pods\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deploy your manifest\n",
    "```\n",
    "kubectl apply -f ./new-nginx-pod.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start an interactive bash shell in the nginx container\n",
    "```\n",
    "kubectl exec -it new-nginx /bin/bash\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set up port forwarding from Cloud Shell to the nginx Pod (from port 10081 of the Cloud Shell VM to port 80 of the nginx container)\n",
    "```\n",
    "kubectl port-forward new-nginx 10081:80\n",
    "```\n",
    "\n",
    "```\n",
    "curl http://127.0.0.1:10081/test.html\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affinity\n",
    "--\n",
    "\n",
    "Pod number one with label app:webserver has both a hard limit and a soft limit. In this pod, the hard limit has an anti-affinity rule, saying that other pods with the label app:webserver aren't allowed in the same zone.  \n",
    "On the other hand, the soft limit has an affinity where it prefers to have other positive label app:cache on the same node.  \n",
    "The cached pods however, prefer to be scheduled on the same node as a webserver but have a hard limit that prevents multiple cache pods from being deployed in the same zone.  \n",
    "The resulting distribution has the two webserver pods repelling each other at the zone level and attracting cache pods at the node level.  \n",
    "Both cache pods also repel each other at the zone level and attract webserver pods at the node level. \n",
    "\n",
    "Pod #1\n",
    "(Label - app: webserver)\n",
    "\n",
    "__Hard limit__ No app:webserver  \n",
    "on the same zone\n",
    "\n",
    "_Soft limit_: Prefer app:cache  \n",
    "one the same node\n",
    "\n",
    "Pod #2\n",
    "(Label - app: webserver)\n",
    "\n",
    "__Hard limit__ No app:webserver  \n",
    "on the same zone\n",
    "\n",
    "_Soft limit_: Prefer app:cache  \n",
    "one the same node\n",
    "\n",
    "Pod #3\n",
    "(Label - app: cache)\n",
    "\n",
    "__Soft limit__ Prefer app:webserver  \n",
    "on the same node\n",
    "\n",
    "_Hard limit_: No app:cache  \n",
    "one the same zone\n",
    "\n",
    "Pod #4\n",
    "(Label - app: cache)\n",
    "\n",
    "__Soft limit__ Prefer app:webserver  \n",
    "on the same node\n",
    "\n",
    "_Hard limit_: No app:cache  \n",
    "one the same zone\n",
    "\n",
    "---\n",
    "\n",
    "Let's walk through the example. Pod one is already running on a node in zone one.  \n",
    "\n",
    "Now pod two is being scheduled. Pods one and two repel each other based on the hard limit. Therefore, pod two is scheduled to run in a different zone, zone two and on a different node.  \n",
    "\n",
    "Pod three has a soft limit preference to run on the same node as webserver pods, so it can be scheduled on the same node as either pod one or pod two. Here, it's scheduled to run alongside pod one.  \n",
    "\n",
    "Finally, pod four has to be scheduled. It will be repelled from pod three with it's hard limit, but can run on a different zone alongside pod two. Additionally, the soft limit has a preference to run on the same node as a webserver pod instead of on a different node.  \n",
    "\n",
    "This allows you to specify affinity rules to co-locate pods at different topological layers and control the distribution of pods across topological layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if the labels on nodes change, affinity and anti-affinity rules will NOT be applied to already-running Pods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
