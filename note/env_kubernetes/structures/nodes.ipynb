{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enable bash autocompletion for kubectl\n",
    "```\n",
    "source <(kubectl completion bash)\n",
    "```\n",
    "\n",
    "view the resource usage across the nodes of the cluster\n",
    "```\n",
    "kubectl top nodes\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node pool\n",
    "--\n",
    "\n",
    "A node pool, is a subset of node instances within a cluster. They all have the same configuration. Node pools use a NodeConfig specification.\n",
    "\n",
    "When you create a container cluster, the number and type of nodes that you specify, becomes a default node pool. Then, you can add additional custom node pools of different sizes and types to your cluster. All nodes at any given node pool are identical to one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you increase the size of a node pool, existing Pods will NOT be moved to newer nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you manually decrease the size of a node pool, any Pods on deleted nodes will NOT be restarted on other nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if autoscaling decreases the size of a node pool, any Pods on deleted nodes that aren't managed by a replication controller will NOT be lost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deploy a new node pool with three preemptible VM instances\n",
    "\n",
    "```\n",
    "gcloud container node-pools create \"temp-pool-1\" \\\n",
    "--cluster=$my_cluster --zone=$my_zone \\\n",
    "--num-nodes \"2\" --node-labels=temp=true --preemptible\n",
    "\n",
    "kubectl get nodes -l temp=true\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control scheduling with taints and tolerations\n",
    "--\n",
    "\n",
    "To prevent the scheduler from running a Pod on the temporary nodes, you add a taint to each of the nodes in the temp pool. Taints are implemented as a key-value pair with an effect (such as NoExecute) that determines whether Pods can run on a certain node. Only nodes that are configured to tolerate the key-value of the taint are scheduled to run on these nodes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
