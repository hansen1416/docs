{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Pod and Deployment are full-fledged objects in the Kubernetes API. Deployment manages creating Pods by means of ReplicaSets. What it boils down to is that Deployment will create Pods with spec taken from the template. It is rather unlikely that you will ever need to create Pods directly for a production use-case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deployment is a higher-level API object that updates its underlying Replica Sets and their Pods in a similar fashion as kubectl rolling-update. Deployments are recommended if you want this rolling update functionality, because unlike kubectl rolling-update, they are declarative, server-side, and have additional features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Deployment configures a ReplicaSet controller to create and maintain a specific version of the Pods that the Deployment specifies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "kubectl apply -f [DEPLOYMENT_FILE]\n",
    "```\n",
    "\n",
    "```\n",
    "kubectl run [DEPLOYMENT_NAME] \\\n",
    "--image [IMAGE]:[TAG] \\\n",
    "--replica 3 \\\n",
    "--labels [KET]=[VALUE] \\\n",
    "--port 8080 \\\n",
    "--generator deployment/apps.v1 \\\n",
    "--save-config\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "kubectl get deployment [DEPLOYMENT_NAME]\n",
    "\n",
    "kubectl get deployment [DEPLOYMENT_NAME] -o yaml > this.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "kubectl get deployment [DEPLOYMENT_NAME]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "kubectl scale deployment [DEPLOYMENT_NAME] --replicas =5\n",
    "\n",
    "kubectl autoscale deployment [DEPLOYMENT_NAME] --min=5 --max=15 --cpu-percent=75\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "updating a deployment\n",
    "\n",
    "```\n",
    "kubectl apply -f [DEPLOYMENT_NAME]\n",
    "\n",
    "kubectl set image deployment [DEPLOYMENT_NAME] [IMAGE] [IMAGE]:[TAG]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rolling update\n",
    "\n",
    "```\n",
    "maxSurge: 5\n",
    "maxUnavailable: 25%\n",
    "\n",
    "```\n",
    "Specifying max unavailable at 25% means you want to have at least 75% of the desired pods running at the same time. The default max unavailable is 25%.  \n",
    "\n",
    "Max surge allows you to specify the maximum number of pods that can be created concurrently in a new replica set.  \n",
    "\n",
    "You can also set max surge as a percentage. The deployment controller looks at the total number of running pods in both ReplicaSets old and new. In this example, a deployment with the desired number of Pods as four and a max surge of 25% will allow a maximum of 5 Pods running at any given time. In other words, it'll allow 125% of the desired number of pods, which is five. Again, the default maxSurge is 25%. Let's look at a deployment with the desired number of pods set to ten, maxUnavailable set to 30% and maxSurge set to 5. The old replica set has 10 pods\n",
    "\n",
    "Deployment  \n",
    "Desired pods = 10 pods  \n",
    "Max unavailable = 30% of disired pods  \n",
    "max surge = 5 pods  \n",
    "\n",
    "total pods = 15 (max)\n",
    "\n",
    "Old ReplicaSet\n",
    "\n",
    "number of pods = 10 - 8 = 2\n",
    "\n",
    "New ReplicaSet\n",
    "\n",
    "number of pods = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rolling back a deployment\n",
    "--\n",
    "\n",
    "```\n",
    "kubectl rollout undo deployment [DEPLOYMENT_NAME]\n",
    "\n",
    "kubectl rollout undo deployment [DEPLOYMENT_NAME] --to-revision=2\n",
    "\n",
    "kubectl rollout history deployment [DEPLOYMENT_NAME] --revision=2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pausing/Resuming a deployment\n",
    "--\n",
    "\n",
    "```\n",
    "kubectl rollout pause deployment [DEPLOYMENT_NAME]\n",
    "\n",
    "kubectl rollout resume deployment [DEPLOYMENT_NAME]\n",
    "\n",
    "kubectl rollout status deployment [DEPLOYMENT_NAME]\n",
    "\n",
    "kubectl rollout delete deployment [DEPLOYMENT_NAME]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Session affinity\n",
    "\n",
    "The Service configuration used in the lab does not ensure that all requests from a single client will always connect to the same Pod. Each request is treated separately and can connect to either the normal nginx deployment or to the nginx-canary deployment. This potential to switch between different versions may cause problems if there are significant changes in functionality in the canary release. To prevent this you can set the sessionAffinity field to ClientIP in the specification of the service if you need a client's first request to determine which Pod will be used for all subsequent connections."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
